---
title: "Chapter 2 Problem 2.2 "
author: Lizhuo Zhou 20307100132
output: pdf_document
date: '2023-10-04'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



\large

## Problem 2.2 a,b,c,d
## Apply the bisection method to solve the parameter. Use additional runs to illustrate manners in which the bisection method may fail to find the global maximum.

### Part (a)
\
\ \ Since the observations are iid according to the density $f(x)$, the log-likelihood function is
$l(\theta)=\sum_{i=1}^{n}log\{1-cos(X_{i}-\theta)\}$. The plot of the log-likelihood is given below:

```{r} 

X <- c(3.91, 4.85, 2.28, 4.06, 3.70, 4.04, 5.46, 3.53, 2.28, 1.96, 2.53,
3.88, 2.22, 3.47, 4.82, 2.46, 2.99, 2.54, 0.52, 2.50)
loglik <- function(x){sum(log(1 - cos(X - x)))}
U <- seq(-pi, pi, len=1000)
loglik.U <- sapply(U, loglik)
plot(U, loglik.U, type="l", xlab=expression(theta), ylab=expression(log~L(theta)))


```
\
\ \ Conclusion:
\
\ \ From the plot above, we could see that the graph is quite bumpy,implying any optimization routine would be highly sensitive to the starting point, as there are many nearby local maxima.

### Part(b)
\
\ \ To derive the method-of-moments estimator $\tilde{\theta}$: 
\
\ \ Setting the mean function $\mu(\theta)=\int xf(x)dx$ equal to the sample mean $\bar{X}$, then solve for $\theta$. 
\
\ \ $\displaystyle \mu(\theta)=\dfrac{1}{2\pi}\int_{0}^{2\pi}x[1-cos(x-\theta)]dx=\pi-\dfrac{1}{2\pi}\int_{0}^{2\pi}xcos(x-\theta)dx$
\
\ \ Respectively,$\displaystyle \int_{0}^{2\pi}xcos(x-\theta)dx=xsin(x-\theta)|^{2\pi}_{0}-\int_{0}^{2\pi}sin(x-\theta)dx=2\pi sin(2\pi-\theta)$
\
\ \ Plug in the original formula:$\displaystyle \mu(\theta)=\pi-\dfrac{1}{2\pi}\int_{0}^{2\pi}xcos(x-\theta)dx=\pi+sin\theta$
\
\ \ Solve for $\tilde{\theta}$: $\mu(\theta)=\bar{X} \Leftrightarrow \pi+sin\theta=\bar{X} \Leftrightarrow \theta=arcsin(\bar{X}-\pi)$
\
\ \ Therefore, the method-of-moments estimator $\tilde{\theta}=arcsin(\bar{X}-\pi)=0.05844061$.


```{r}
### Apply the bisection method to solve the parameter

FOD_like <- function(x){-sum(sin(X - x) / (1 - cos(X - x)))}
SOD_like<- function(x){-sum(1 / (1 - cos(X - x)))}


# Function to implement the BISECTION method

bisection <- function (f, a, b, eps=1e-08, maxiter=1000){
  x <- (a + b) / 2
  t <- 0
  repeat {
    t <- t + 1
    if(f(a) * f(x) <= 0){b <- x} else{ a <- x}
    x.new <- (a + b) / 2
    if(abs(x.new - x) < eps | t >= maxiter) {
      if(t >= maxiter) warning("Maximum number of iterations reached!")
      break
    }
    x <- x.new
  }
  out <- list(solution=x.new, value=f(x.new), iter=t)
  return(out)
}

bisection(FOD_like,-pi,pi)
bisection(FOD_like,-3,3)
bisection(FOD_like,-1,2)
bisection(FOD_like,0,1)
bisection(FOD_like,-1.5,1.5)
bisection(FOD_like,0.1,3)
bisection(FOD_like,-0.1,1.5)
bisection(FOD_like,-0.1,0.1)

```
\
\ \ Conclusion:
\
\ \ Under this scenario,the bisection method is highly sensitive to the range we have chosen, and different ranges would lead to very distinct results. Arbitrarily chosen range will most likely result in a local maxima rather than the global maxima. Only starting points close enough to the global maxima will end up in the optimum we intended to get. When the initial interval we have chosen is far away from the global maxima, the bisection method would fail.


### Part(c)


```{r} 
mme<-asin(mean(X)-pi)


# Function to implement NEWTON'S method

Newton <- function(f, df, startpoint, eps=1e-08, maxiter=1000) {
  x <- startpoint
  t <- 0
  repeat {
    t <- t + 1
    x.new <- x - f(x) / df(x)
    if(abs(x.new - x) < eps | t >= maxiter) {
      if(t >= maxiter) warning("Maximum number of iterations reached!")
      break
    }
    x <- x.new
  }
  out <- list(solution=x.new, value=f(x.new), iter=t)
  return(out)
}

Newton(FOD_like,SOD_like,mme)
Newton(FOD_like,SOD_like,-2.7)
Newton(FOD_like,SOD_like,2.7)

```
\
\ \ Conclusion:
\
\ \  Using the starting value $\theta^{(0)}=\tilde{\theta}=0.05844061$, the method-of-moments estimator, Newtonâ€™s method converges to $\hat{\theta}=-0.011972$. Alternatively, if we start with $\theta^{(0)}=-2.7,2.7$, the ending estimates are $\hat{\theta}=-2.6667,2.873095$, respectively.

### Part (d)

```{r}
# Table: Partition of the interval [-pi,pi]
U <- seq(-pi, pi, len=200)

N <- function(x) {round(Newton(FOD_like, SOD_like, x)$solution, 4)}
theta <- sapply(U, N)
theta
soln <- split(U, theta)
m <- sapply(soln, min)
M <- sapply(soln, max)
cbind(min=round(m,6), max=round(M,6))

```
\
\ \ Conclusion:
\
\ \ For 200 equally-spaced starting values between $-\pi$ and $\pi$, we get 20 different
solutions, denoted by $\hat{\theta_{1}},...\hat{\theta_{20}}$. We may partition the interval $[-\pi,\pi]$ into
subintervals $S_{i},i=1,2,...,20$ based on the following condition: 
\
\ \ $\theta \in S_{i}$ if and only if $\theta^{(0)}=\theta$ implies $\theta^{t} \rightarrow \hat{\theta_{i}}$
\
\ \ The table above shows $\theta_{i}$ as well as the estimates of the upper and lower bounds of the corresponding $S_{i}$. Note that the method-of-moments estimator $\tilde{\theta}$ belongs to $S_{12}$.





